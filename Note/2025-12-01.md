# 视频理解模型

## agent
- [LVAgent](https://github.com/64327069/LVAgent)
- [Video-MTR](https://arxiv.org/pdf/2508.20478)

---
## benchmark
- [TempCompass](https://arxiv.org/pdf/2403.00476)
- [Vitatecs](https://arxiv.org/pdf/2311.17404)
- [EgoSchema](https://arxiv.org/pdf/2308.09126)
- [MVBench](https://arxiv.org/pdf/2311.17005)
- [Video-MME](https://arxiv.org/pdf/2405.21075)
- [LongVideoBench](https://arxiv.org/pdf/2407.15754)
- [MLVU](https://arxiv.org/pdf/2406.04264)

---
## model
- [LongCat-Flash-Omni](https://arxiv.org/pdf/2511.00279)
- [Gemma 3](https://arxiv.org/pdf/2503.19786)
- [Gemini 2.5](https://arxiv.org/pdf/2507.06261)
- [Qwen3-Omni](https://arxiv.org/pdf/2509.17765)
- [MiniCPM-V 4.5](https://arxiv.org/pdf/2509.18154)
- [Ming-Omni](https://arxiv.org/pdf/2506.09344)
- [GPT-4o](https://arxiv.org/pdf/2410.21276)
- [VITA-1.5](https://arxiv.org/pdf/2501.01957)
- [Ola](https://arxiv.org/pdf/2502.04328)
- [M2-omni](https://arxiv.org/pdf/2502.18778)
- [Seed1.5-VL](https://arxiv.org/pdf/2505.07062)
- [InternVL3.5](https://arxiv.org/pdf/2508.18265)
- [VideoChat-Flash](https://github.com/OpenGVLab/VideoChat-Flash)
- [VideoLLaMA3](https://github.com/DAMO-NLP-SG/VideoLLaMA3) 
- [Oryx](https://github.com/Oryx-mllm/Oryx)
- [Aria](https://github.com/rhymes-ai/Aria)
- [Video-XL](https://github.com/VectorSpaceLab/Video-XL)
- [LLaVA-NeXT](https://github.com/LLaVA-VL/LLaVA-NeXT)
- [MiniCPM-V](https://github.com/OpenBMB/MiniCPM-V)
- [LongVU](https://github.com/Vision-CAIR/LongVU)
- [GLM-V](https://github.com/zai-org/GLM-V)
- [LinVT](https://github.com/gls0425/LinVT)
- [VILA](https://github.com/NVlabs/VILA)
